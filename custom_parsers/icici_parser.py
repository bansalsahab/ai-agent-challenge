# Autogenerated by agent.py â€” safe to edit
"""Parser for target: icici

Provides:
- parse(pdf_path: str) -> pandas.DataFrame
- Date normalization (string)
- Amount normalization to float
"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from typing import Dict, List, Optional

import numpy as np
import pandas as pd

LOGGER = logging.getLogger(__name__)

# EXPECTED_COLUMNS: exact column names + order the parser must return
EXPECTED_COLUMNS: List[str] = ['Date', 'Description', 'Debit Amt', 'Credit Amt', 'Balance']

# EXPECTED_DTYPES: simple categories used for casting in parse()
EXPECTED_DTYPES: Dict[str, str] = {
    'Date': 'date',
    'Description': 'str',
    'Debit Amt': 'float',
    'Credit Amt': 'float',
    'Balance': 'float'
}

# COLUMN_MAP: optional mapping from parsed column tokens -> expected column name
# The agent may update this dict programmatically during self-fix attempts.
COLUMN_MAP: Dict[str, str] = {}
# AUTOFIX_MARKER

def _standardize_token(s: str) -> str:
    if s is None:
        return ""
    return re.sub(r"[^0-9a-z]", "", str(s).lower().strip())

def _normalize_amount(val) -> float:
    if pd.isna(val):
        return float('nan')
    try:
        s = str(val)
        s = re.sub(r"[^\d\.-]", "", s)
        if s == "" or s == "-":
            return float('nan')
        return float(s)
    except Exception:
        return float('nan')

def _normalize_date(val) -> Optional[str]:
    if pd.isna(val):
        return np.nan
    try:
        parsed = pd.to_datetime(str(val), errors='coerce', dayfirst=True)
        if pd.isna(parsed):
            parsed = pd.to_datetime(str(val), errors='coerce', dayfirst=False)
        if pd.isna(parsed):
            return np.nan
        return parsed.strftime('%d-%m-%Y')
    except Exception:
        return np.nan

def _apply_column_map(df: pd.DataFrame) -> pd.DataFrame:
    if not COLUMN_MAP:
        return df
    rename = {}
    for c in df.columns:
        token = _standardize_token(c)
        if token in COLUMN_MAP:
            rename[c] = COLUMN_MAP[token]
    if rename:
        df = df.rename(columns=rename)
    return df

def _coerce_dtypes(df: pd.DataFrame) -> pd.DataFrame:
    for col, kind in EXPECTED_DTYPES.items():
        if col not in df.columns:
            continue
        if kind == 'date':
            df[col] = df[col].apply(_normalize_date)
        elif kind == 'float':
            df[col] = df[col].apply(_normalize_amount)
        else:
            df[col] = df[col].astype(str).where(df[col].notna(), other=np.nan)
    return df

def parse(pdf_path: str) -> pd.DataFrame:
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF not found: {pdf_path}")

    parsed_df = None
    try:
        import pdfplumber
        with pdfplumber.open(str(pdf_path)) as doc:
            tables = []
            for page in doc.pages:
                try:
                    page_tables = page.extract_tables()
                except Exception:
                    try:
                        t = page.extract_table()
                        page_tables = [t] if t else []
                    except Exception:
                        page_tables = []
                for tbl in page_tables or []:
                    if not tbl:
                        continue
                    header = tbl[0]
                    rows = tbl[1:]
                    if not header or not rows:
                        continue
                    df = pd.DataFrame(rows, columns=header)
                    tables.append(df)
            if tables:
                tables.sort(key=lambda d: len(d), reverse=True)
                parsed_df = pd.concat(tables, ignore_index=True)
    except Exception:
        pass

    if parsed_df is None or parsed_df.empty:
        try:
            from pdf2image import convert_from_path
            import pytesseract
            from PIL import Image
            images = convert_from_path(str(pdf_path))
            text_lines = []
            for img in images:
                txt = pytesseract.image_to_string(img)
                for line in txt.splitlines():
                    line = line.strip()
                    if line:
                        text_lines.append(line)
            rows = []
            date_re = re.compile(r"(\d{1,2}[\-/]\d{1,2}[\-/]\d{2,4})")
            amount_re = re.compile(r"[\-]?[\d,]+\.\d{2}")
            for line in text_lines:
                parts = re.split(r"\s{2,}|	", line)
                if len(parts) >= 3:
                    rows.append(parts)
                else:
                    if date_re.search(line) and amount_re.search(line):
                        parts = re.split(r"\s+", line)
                        rows.append(parts)
            if rows:
                max_cols = max(len(r) for r in rows)
                header = [f"col{i}" for i in range(max_cols)]
                parsed_df = pd.DataFrame([r + [None] * (max_cols - len(r)) for r in rows], columns=header)
        except Exception:
            parsed_df = pd.DataFrame(columns=EXPECTED_COLUMNS)

    parsed_df.columns = [str(c).strip() for c in parsed_df.columns]
    parsed_df = _apply_column_map(parsed_df)

    parsed_tokens = {_standardize_token(c): c for c in parsed_df.columns}
    for expected in EXPECTED_COLUMNS:
        token = _standardize_token(expected)
        if token in parsed_tokens:
            if parsed_tokens[token] != expected:
                parsed_df = parsed_df.rename(columns={parsed_tokens[token]: expected})

    parsed_df = parsed_df.reindex(columns=EXPECTED_COLUMNS)
    parsed_df = _coerce_dtypes(parsed_df)
    parsed_df = parsed_df.reset_index(drop=True)
    return parsed_df
